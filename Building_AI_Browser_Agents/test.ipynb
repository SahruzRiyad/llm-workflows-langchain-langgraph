{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74385c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebScraperAgent:\n",
    "    def __init__(self):\n",
    "        self.playwright = None\n",
    "        self.browser = None\n",
    "        self.page = None\n",
    "\n",
    "    async def init_browser(self):\n",
    "        try:\n",
    "            self.playwright = await async_playwright().start()\n",
    "            self.browser = await self.playwright.chromium.launch(\n",
    "                headless=True,\n",
    "                args=[\n",
    "                    \"--disable-dev-shm-usage\",\n",
    "                    \"--no-sandbox\",\n",
    "                    \"--disable-setuid-sandbox\",\n",
    "                    \"--disable-gpu\",  # Simplified args\n",
    "                ]\n",
    "            )\n",
    "            self.page = await self.browser.new_page()\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Browser initialization failed: {str(e)}\")\n",
    "            await self.safe_close()\n",
    "            return False\n",
    "\n",
    "    async def safe_close(self):\n",
    "        \"\"\"Safe cleanup that handles partial initialization\"\"\"\n",
    "        try:\n",
    "            if hasattr(self, 'page') and self.page and not self.page.is_closed():\n",
    "                await self.page.close()\n",
    "            if hasattr(self, 'browser') and self.browser:\n",
    "                await self.browser.close()\n",
    "            if hasattr(self, 'playwright') and self.playwright:\n",
    "                await self.playwright.stop()\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Cleanup error: {str(e)}\")\n",
    "        finally:\n",
    "            self.page = None\n",
    "            self.browser = None\n",
    "            self.playwright = None\n",
    "\n",
    "    async def scrape_content(self, url):\n",
    "        if not await self.init_browser():\n",
    "            raise RuntimeError(\"Browser not initialized\")\n",
    "        \n",
    "        try:\n",
    "            await self.page.goto(url, wait_until=\"domcontentloaded\")\n",
    "            await self.page.wait_for_load_state(\"networkidle\", timeout=5000)\n",
    "            return await self.page.content()\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Scraping failed: {str(e)}\")\n",
    "            await self.safe_close()\n",
    "            raise\n",
    "\n",
    "async def webscraper(target_url, instructions):\n",
    "    scraper = WebScraperAgent()\n",
    "    try:\n",
    "        print(\"Initializing browser...\")\n",
    "        if not await scraper.init_browser():\n",
    "            return None, None\n",
    "\n",
    "        print(\"Extracting HTML content...\")\n",
    "        html_content = await scraper.scrape_content(target_url)\n",
    "\n",
    "        print(\"Taking screenshot...\")\n",
    "        screenshot = await scraper.page.screenshot(type=\"png\")\n",
    "\n",
    "        print(\"Processing with LLM...\")\n",
    "        result = await process_with_llm(html_content, instructions, False)\n",
    "        print(\"✅ Done!\")\n",
    "        return result, screenshot\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Fatal error: {str(e)}\")\n",
    "        return None, None\n",
    "    finally:\n",
    "        await scraper.safe_close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
